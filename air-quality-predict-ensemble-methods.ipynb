{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe8cb4bc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.467096,
     "end_time": "2024-09-18T12:50:39.386793",
     "exception": false,
     "start_time": "2024-09-18T12:50:38.919697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81eaf036",
   "metadata": {
    "papermill": {
     "duration": 0.092781,
     "end_time": "2024-09-18T12:50:39.486427",
     "exception": false,
     "start_time": "2024-09-18T12:50:39.393646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AQI</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2_5</th>\n",
       "      <th>NO2</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RespiratoryCases</th>\n",
       "      <th>CardiovascularCases</th>\n",
       "      <th>HospitalAdmissions</th>\n",
       "      <th>HealthImpactScore</th>\n",
       "      <th>HealthImpactClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>187.270059</td>\n",
       "      <td>295.853039</td>\n",
       "      <td>13.038560</td>\n",
       "      <td>6.639263</td>\n",
       "      <td>66.161150</td>\n",
       "      <td>54.624280</td>\n",
       "      <td>5.150335</td>\n",
       "      <td>84.424344</td>\n",
       "      <td>6.137755</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>97.244041</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>475.357153</td>\n",
       "      <td>246.254703</td>\n",
       "      <td>9.984497</td>\n",
       "      <td>16.318326</td>\n",
       "      <td>90.499523</td>\n",
       "      <td>169.621728</td>\n",
       "      <td>1.543378</td>\n",
       "      <td>46.851415</td>\n",
       "      <td>4.521422</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>365.996971</td>\n",
       "      <td>84.443191</td>\n",
       "      <td>23.111340</td>\n",
       "      <td>96.317811</td>\n",
       "      <td>17.875850</td>\n",
       "      <td>9.006794</td>\n",
       "      <td>1.169483</td>\n",
       "      <td>17.806977</td>\n",
       "      <td>11.157384</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>299.329242</td>\n",
       "      <td>21.020609</td>\n",
       "      <td>14.273403</td>\n",
       "      <td>81.234403</td>\n",
       "      <td>48.323616</td>\n",
       "      <td>93.161033</td>\n",
       "      <td>21.925276</td>\n",
       "      <td>99.473373</td>\n",
       "      <td>15.302500</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.009320</td>\n",
       "      <td>16.987667</td>\n",
       "      <td>152.111623</td>\n",
       "      <td>121.235461</td>\n",
       "      <td>90.866167</td>\n",
       "      <td>241.795138</td>\n",
       "      <td>9.217517</td>\n",
       "      <td>24.906837</td>\n",
       "      <td>14.534733</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>95.182643</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AQI        PM10       PM2_5         NO2        SO2          O3  \\\n",
       "0  187.270059  295.853039   13.038560    6.639263  66.161150   54.624280   \n",
       "1  475.357153  246.254703    9.984497   16.318326  90.499523  169.621728   \n",
       "2  365.996971   84.443191   23.111340   96.317811  17.875850    9.006794   \n",
       "3  299.329242   21.020609   14.273403   81.234403  48.323616   93.161033   \n",
       "4   78.009320   16.987667  152.111623  121.235461  90.866167  241.795138   \n",
       "\n",
       "   Temperature   Humidity  WindSpeed  RespiratoryCases  CardiovascularCases  \\\n",
       "0     5.150335  84.424344   6.137755                 7                    5   \n",
       "1     1.543378  46.851415   4.521422                10                    2   \n",
       "2     1.169483  17.806977  11.157384                13                    3   \n",
       "3    21.925276  99.473373  15.302500                 8                    8   \n",
       "4     9.217517  24.906837  14.534733                 9                    0   \n",
       "\n",
       "   HospitalAdmissions  HealthImpactScore  HealthImpactClass  \n",
       "0                   1          97.244041                0.0  \n",
       "1                   0         100.000000                0.0  \n",
       "2                   0         100.000000                0.0  \n",
       "3                   1         100.000000                0.0  \n",
       "4                   1          95.182643                0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:/Machin Language Projects/air quality/air_quality_health_impact_data.csv')\n",
    "pd.set_option('max_colwidth', 100)\n",
    "df = df.drop(columns=['RecordID'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6afa64d0",
   "metadata": {
    "papermill": {
     "duration": 1.304284,
     "end_time": "2024-09-18T12:50:40.797002",
     "exception": false,
     "start_time": "2024-09-18T12:50:39.492718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fd532d1",
   "metadata": {
    "papermill": {
     "duration": 0.028254,
     "end_time": "2024-09-18T12:50:40.831818",
     "exception": false,
     "start_time": "2024-09-18T12:50:40.803564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Özellikler ve hedef değişkeni belirleme\n",
    "X = df.drop(columns=['HealthImpactClass'])\n",
    "y = df['HealthImpactClass']\n",
    "\n",
    "# Veri setini eğitim ve test olarak ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=58)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5fcac9",
   "metadata": {
    "papermill": {
     "duration": 0.005981,
     "end_time": "2024-09-18T12:50:40.844127",
     "exception": false,
     "start_time": "2024-09-18T12:50:40.838146",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1) Boosting\n",
    "\n",
    "Boosting, zayıf öğrenicileri (weak learners) güçlü bir tahminciye dönüştürmeyi amaçlayan bir makine öğrenimi topluluk (ensemble) tekniğidir. Boosting, her bir zayıf öğrenicinin hatalarını düzelterek modelin doğruluğunu artırır.\n",
    "\n",
    "Boosting'in prensipleri şunlardır:\n",
    "\n",
    "- Adım Adım Öğrenme: Boosting, zayıf öğrenicileri ardışık olarak eğitir. Her yeni model, önceki modellerin hatalarını düzelterek daha iyi tahmin yapmaya çalışır.\n",
    "- Ağırlıklandırma: Her bir örneğin hata oranına göre ağırlıklandırılır. Hatalı sınıflandırılmış örnekler daha yüksek ağırlık alır, böylece sonraki model bu örnekleri daha iyi öğrenir.\n",
    "- Topluluk Kararı: Nihai tahmin, tüm zayıf öğrenicilerin tahminlerinin ağırlıklı toplamı veya çoğunluk kararı ile belirlenir.\n",
    "\n",
    "### 1.1 Gradient Boosting\n",
    "\n",
    "Gradient Boosting, zayıf modellerin ardışık olarak eğitilmesiyle güçlü bir model oluşturur. Her bir model, önceki modellerin hatalarını düzelterek öğrenir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8abd945",
   "metadata": {
    "papermill": {
     "duration": 11.313537,
     "end_time": "2024-09-18T12:50:52.163869",
     "exception": false,
     "start_time": "2024-09-18T12:50:40.850332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[948   5   3   7   3]\n",
      " [  6 103   0   2   0]\n",
      " [ 10   3  42   0   1]\n",
      " [  6   1   0   7   0]\n",
      " [ 15   1   0   0   0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.98      0.97       966\n",
      "         1.0       0.91      0.93      0.92       111\n",
      "         2.0       0.93      0.75      0.83        56\n",
      "         3.0       0.44      0.50      0.47        14\n",
      "         4.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.95      1163\n",
      "   macro avg       0.65      0.63      0.64      1163\n",
      "weighted avg       0.94      0.95      0.94      1163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Gradient Boosting modelini oluşturma\n",
    "gb_model = GradientBoostingClassifier(random_state=58)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Tahmin yapma\n",
    "y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Sonuçları değerlendirme\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc83407",
   "metadata": {
    "papermill": {
     "duration": 0.006096,
     "end_time": "2024-09-18T12:50:52.176436",
     "exception": false,
     "start_time": "2024-09-18T12:50:52.170340",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.2 AdaBoost\n",
    "\n",
    "AdaBoost, zayıf öğreniciler (genellikle decision tree'ler) kullanarak ardışık olarak modeller oluşturur ve her adımda hataları düzelterek güçlü bir model oluşturur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd053eba",
   "metadata": {
    "papermill": {
     "duration": 0.646591,
     "end_time": "2024-09-18T12:50:52.829409",
     "exception": false,
     "start_time": "2024-09-18T12:50:52.182818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[939   1   5   0  21]\n",
      " [  8 100   2   0   1]\n",
      " [ 10   2  39   0   5]\n",
      " [  6   1   1   6   0]\n",
      " [ 15   0   0   0   1]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.97      0.97       966\n",
      "         1.0       0.96      0.90      0.93       111\n",
      "         2.0       0.83      0.70      0.76        56\n",
      "         3.0       1.00      0.43      0.60        14\n",
      "         4.0       0.04      0.06      0.05        16\n",
      "\n",
      "    accuracy                           0.93      1163\n",
      "   macro avg       0.76      0.61      0.66      1163\n",
      "weighted avg       0.94      0.93      0.94      1163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# AdaBoost modelini oluşturma\n",
    "ab_model = AdaBoostClassifier(random_state=58)\n",
    "ab_model.fit(X_train, y_train)\n",
    "\n",
    "# Tahmin yapma\n",
    "y_pred = ab_model.predict(X_test)\n",
    "\n",
    "# Sonuçları değerlendirme\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9b8e7e",
   "metadata": {
    "papermill": {
     "duration": 0.00627,
     "end_time": "2024-09-18T12:50:52.842205",
     "exception": false,
     "start_time": "2024-09-18T12:50:52.835935",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.3 XGBoost\n",
    "\n",
    "XGBoost, performans ve hız açısından oldukça güçlü bir boosting algoritmasıdır. Aynı zamanda eksik verilerle başa çıkma yeteneği de vardır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eca00101",
   "metadata": {
    "papermill": {
     "duration": 0.778549,
     "end_time": "2024-09-18T12:50:53.627352",
     "exception": false,
     "start_time": "2024-09-18T12:50:52.848803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[964   1   1   0   0]\n",
      " [  7 104   0   0   0]\n",
      " [ 10   3  43   0   0]\n",
      " [  6   1   0   7   0]\n",
      " [ 16   0   0   0   0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98       966\n",
      "         1.0       0.95      0.94      0.95       111\n",
      "         2.0       0.98      0.77      0.86        56\n",
      "         3.0       1.00      0.50      0.67        14\n",
      "         4.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.96      1163\n",
      "   macro avg       0.78      0.64      0.69      1163\n",
      "weighted avg       0.95      0.96      0.95      1163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# XGBoost modelini oluşturma\n",
    "xgb_model = xgb.XGBClassifier(random_state=58)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Tahmin yapma\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Sonuçları değerlendirme\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1690fb6f",
   "metadata": {
    "papermill": {
     "duration": 0.006261,
     "end_time": "2024-09-18T12:50:53.640189",
     "exception": false,
     "start_time": "2024-09-18T12:50:53.633928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2) Majority Voting\n",
    "\n",
    "Majority voting ensemble, birden fazla makine öğrenimi modelinin tahminlerini birleştirerek nihai sınıflandırma kararını veren bir ensemble yöntemidir. Bu yöntemde, her bir modelin verdiği sınıf tahminleri alınır ve en çok oy alan sınıf, nihai tahmin olarak seçilir. Bu yaklaşım, farklı modellerin güçlü yönlerini birleştirerek daha doğru ve sağlam bir tahmin yapmayı amaçlar.\n",
    "\n",
    "Çalışma Prensibi\n",
    "Farklı Modellerin Eğitimi: Farklı türde makine öğrenimi modelleri (örneğin, decision tree, k-nearest neighbors, logistic regression) aynı veri seti üzerinde eğitilir.\n",
    "Tahminlerin Alınması: Test verileri üzerinde her bir modelin tahminleri yapılır.\n",
    "Oyların Birleştirilmesi: Her bir veri noktası için modellerin yaptığı tahminler alınır ve en çok oyu alan sınıf, nihai tahmin olarak belirlenir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65db69c6",
   "metadata": {
    "papermill": {
     "duration": 25.626679,
     "end_time": "2024-09-18T12:51:19.273304",
     "exception": false,
     "start_time": "2024-09-18T12:50:53.646625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[964   1   1   0   0]\n",
      " [  9 102   0   0   0]\n",
      " [ 12  11  33   0   0]\n",
      " [  6   1   3   4   0]\n",
      " [ 16   0   0   0   0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98       966\n",
      "         1.0       0.89      0.92      0.90       111\n",
      "         2.0       0.89      0.59      0.71        56\n",
      "         3.0       1.00      0.29      0.44        14\n",
      "         4.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.95      1163\n",
      "   macro avg       0.75      0.56      0.61      1163\n",
      "weighted avg       0.93      0.95      0.94      1163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Veri setini yükleyin ve bağımlı ve bağımsız değişkenleri ayır\n",
    "X = df.drop(columns=['HealthImpactClass'])\n",
    "y = df['HealthImpactClass']\n",
    "\n",
    "# Veri setini eğitim ve test olarak ayır\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=58)\n",
    "\n",
    "# Modelleri tanımla\n",
    "log_clf = LogisticRegression(random_state=58, max_iter=10000)\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "dt_clf = DecisionTreeClassifier(random_state=58)\n",
    "\n",
    "# Majority Voting Ensemble oluştur\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('knn', knn_clf), ('dt', dt_clf)],\n",
    "    voting='hard'  # 'hard' majority voting, 'soft' probability averaging\n",
    ")\n",
    "\n",
    "# Ansambl modelini eğit\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Tahmin yapın\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Sonuçları değerlendir\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12194872",
   "metadata": {
    "papermill": {
     "duration": 0.006519,
     "end_time": "2024-09-18T12:51:19.286611",
     "exception": false,
     "start_time": "2024-09-18T12:51:19.280092",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3) Bagging (Bootstrap Aggregating)\n",
    "\n",
    "Bagging yöntemi, modelin genel performansını artırmak amacıyla birden fazla modelin aynı veri setinden rastgele seçilmiş alt örnekler üzerinde eğitildiği bir ensemble yöntemidir. Bagging, overfitting riskini azaltarak modelin genelleme yeteneğini artırır. Bu yöntem, özellikle yüksek varyansa sahip modellerde etkili sonuçlar verir.\n",
    "Bu yönteme örnek olarak Random Forest’ı ayrı bir .ipynb dosyasında kullandım. Random Forest da bir bagging yöntemidir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2478dab",
   "metadata": {
    "papermill": {
     "duration": 0.006642,
     "end_time": "2024-09-18T12:51:19.299968",
     "exception": false,
     "start_time": "2024-09-18T12:51:19.293326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4) Stacking\n",
    "\n",
    "Stacking, birden fazla modelin tahminlerini bir araya getirerek, nihai tahmini yapmak için bu tahminleri ikinci bir modelle (meta-learner) öğrenen bir ensemble yöntemidir. Stacking, temel öğrenicilerin (base learners) zayıf yanlarını telafi ederek genel model performansını artırmayı amaçlar.\n",
    "\n",
    "Stacking'in Adımları\n",
    "Temel Öğrenicilerin Eğitimi (Base Learners):\n",
    "\n",
    "Farklı algoritmalardan bir dizi temel model (örneğin, lojistik regresyon, SVM, karar ağaçları) eğitilir.\n",
    "Bu modeller veri setinin farklı özelliklerini yakalamaya çalışır.\n",
    "Meta Öğrenicinin Eğitimi (Meta-Learner):\n",
    "\n",
    "Temel öğrenicilerin tahminleri bir araya getirilir ve bu tahminler, yeni bir model (meta-learner) ile birleştirilir.\n",
    "Meta-learner, temel öğrenicilerin tahminlerine dayanarak nihai tahmini yapar.\n",
    "\n",
    "Stacking, çok sınıflı veri setlerinde farklı model türlerinin güçlü yönlerini bir araya getirerek daha iyi bir genel performans sağlayabilir. Özellikle bu veri setinde, çeşitli hava kalitesi ve sağlık etkisi ölçümlerine dayanan çok sayıda sınıf bulunduğundan, stacking gibi bir ensemble yöntemi, sınıflandırma performansını artırmada etkili olabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5bcbe35",
   "metadata": {
    "papermill": {
     "duration": 8.151391,
     "end_time": "2024-09-18T12:51:27.458119",
     "exception": false,
     "start_time": "2024-09-18T12:51:19.306728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[964   1   1   0   0]\n",
      " [  9 102   0   0   0]\n",
      " [ 10   4  42   0   0]\n",
      " [  6   1   0   7   0]\n",
      " [ 16   0   0   0   0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98       966\n",
      "         1.0       0.94      0.92      0.93       111\n",
      "         2.0       0.98      0.75      0.85        56\n",
      "         3.0       1.00      0.50      0.67        14\n",
      "         4.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.96      1163\n",
      "   macro avg       0.78      0.63      0.68      1163\n",
      "weighted avg       0.95      0.96      0.95      1163\n",
      "\n",
      "Model has been saved to stacking_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib  # Import joblib for saving the model\n",
    "\n",
    "# Veri setini yükleme\n",
    "# df = pd.read_csv('path_to_dataset.csv')\n",
    "\n",
    "# Özellikler ve hedef değişkeni belirleme\n",
    "X = df.drop(columns=['HealthImpactClass'])\n",
    "y = df['HealthImpactClass']\n",
    "\n",
    "# Veri setini eğitim ve test olarak ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=58)\n",
    "\n",
    "# Temel öğrenicileri tanımlama\n",
    "estimators = [\n",
    "    ('lr', LogisticRegression(max_iter=1000, random_state=58)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('dt', DecisionTreeClassifier(random_state=58))\n",
    "]\n",
    "\n",
    "# StackingClassifier'ı tanımlama\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(max_iter=1000, random_state=58),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Modeli eğitme\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Tahmin yapma\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "\n",
    "# Sonuçları değerlendirme\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Modeli pkl dosyasına kaydetme\n",
    "model_filename = 'stacking_model.pkl'\n",
    "joblib.dump(stacking_clf, model_filename)\n",
    "print(f\"Model has been saved to {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01db38ab",
   "metadata": {
    "papermill": {
     "duration": 0.01492,
     "end_time": "2024-09-18T12:51:27.488801",
     "exception": false,
     "start_time": "2024-09-18T12:51:27.473881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AQI</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2_5</th>\n",
       "      <th>NO2</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>RespiratoryCases</th>\n",
       "      <th>CardiovascularCases</th>\n",
       "      <th>HospitalAdmissions</th>\n",
       "      <th>HealthImpactScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>20.975612</td>\n",
       "      <td>186.994330</td>\n",
       "      <td>166.287124</td>\n",
       "      <td>25.023232</td>\n",
       "      <td>23.810563</td>\n",
       "      <td>289.637143</td>\n",
       "      <td>27.244114</td>\n",
       "      <td>88.407586</td>\n",
       "      <td>8.258407</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>89.130981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105</th>\n",
       "      <td>331.912237</td>\n",
       "      <td>36.755743</td>\n",
       "      <td>144.606886</td>\n",
       "      <td>92.895229</td>\n",
       "      <td>53.317759</td>\n",
       "      <td>113.354413</td>\n",
       "      <td>5.748297</td>\n",
       "      <td>17.671456</td>\n",
       "      <td>4.323641</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>487.197404</td>\n",
       "      <td>242.639833</td>\n",
       "      <td>69.798987</td>\n",
       "      <td>103.431194</td>\n",
       "      <td>30.291707</td>\n",
       "      <td>293.535944</td>\n",
       "      <td>14.792186</td>\n",
       "      <td>99.756776</td>\n",
       "      <td>13.108582</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>12.693178</td>\n",
       "      <td>4.837394</td>\n",
       "      <td>131.118790</td>\n",
       "      <td>145.470703</td>\n",
       "      <td>94.978710</td>\n",
       "      <td>282.354123</td>\n",
       "      <td>17.381739</td>\n",
       "      <td>67.895914</td>\n",
       "      <td>10.603093</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>76.647627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>252.397799</td>\n",
       "      <td>37.963593</td>\n",
       "      <td>141.740858</td>\n",
       "      <td>81.201155</td>\n",
       "      <td>56.605416</td>\n",
       "      <td>202.773220</td>\n",
       "      <td>28.868166</td>\n",
       "      <td>61.510565</td>\n",
       "      <td>6.120312</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5210</th>\n",
       "      <td>473.843089</td>\n",
       "      <td>12.601730</td>\n",
       "      <td>114.675358</td>\n",
       "      <td>5.326337</td>\n",
       "      <td>45.759913</td>\n",
       "      <td>40.140420</td>\n",
       "      <td>32.882702</td>\n",
       "      <td>48.581990</td>\n",
       "      <td>2.151754</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>420.454355</td>\n",
       "      <td>6.488098</td>\n",
       "      <td>113.240965</td>\n",
       "      <td>74.545341</td>\n",
       "      <td>49.103362</td>\n",
       "      <td>64.147984</td>\n",
       "      <td>1.844158</td>\n",
       "      <td>77.755383</td>\n",
       "      <td>3.547843</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2965</th>\n",
       "      <td>350.584931</td>\n",
       "      <td>292.107640</td>\n",
       "      <td>36.153984</td>\n",
       "      <td>167.770317</td>\n",
       "      <td>69.537853</td>\n",
       "      <td>32.846913</td>\n",
       "      <td>-6.544956</td>\n",
       "      <td>13.474710</td>\n",
       "      <td>2.212371</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3982</th>\n",
       "      <td>112.159279</td>\n",
       "      <td>79.363886</td>\n",
       "      <td>52.918207</td>\n",
       "      <td>72.211940</td>\n",
       "      <td>32.469286</td>\n",
       "      <td>106.022767</td>\n",
       "      <td>19.174126</td>\n",
       "      <td>56.485073</td>\n",
       "      <td>13.930092</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>69.959538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3875</th>\n",
       "      <td>209.591438</td>\n",
       "      <td>85.657522</td>\n",
       "      <td>5.290901</td>\n",
       "      <td>189.572554</td>\n",
       "      <td>83.084628</td>\n",
       "      <td>191.134972</td>\n",
       "      <td>4.633405</td>\n",
       "      <td>54.526187</td>\n",
       "      <td>15.758153</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4648 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AQI        PM10       PM2_5         NO2        SO2          O3  \\\n",
       "1826   20.975612  186.994330  166.287124   25.023232  23.810563  289.637143   \n",
       "4105  331.912237   36.755743  144.606886   92.895229  53.317759  113.354413   \n",
       "498   487.197404  242.639833   69.798987  103.431194  30.291707  293.535944   \n",
       "874    12.693178    4.837394  131.118790  145.470703  94.978710  282.354123   \n",
       "2987  252.397799   37.963593  141.740858   81.201155  56.605416  202.773220   \n",
       "...          ...         ...         ...         ...        ...         ...   \n",
       "5210  473.843089   12.601730  114.675358    5.326337  45.759913   40.140420   \n",
       "3828  420.454355    6.488098  113.240965   74.545341  49.103362   64.147984   \n",
       "2965  350.584931  292.107640   36.153984  167.770317  69.537853   32.846913   \n",
       "3982  112.159279   79.363886   52.918207   72.211940  32.469286  106.022767   \n",
       "3875  209.591438   85.657522    5.290901  189.572554  83.084628  191.134972   \n",
       "\n",
       "      Temperature   Humidity  WindSpeed  RespiratoryCases  \\\n",
       "1826    27.244114  88.407586   8.258407                 6   \n",
       "4105     5.748297  17.671456   4.323641                 9   \n",
       "498     14.792186  99.756776  13.108582                16   \n",
       "874     17.381739  67.895914  10.603093                11   \n",
       "2987    28.868166  61.510565   6.120312                14   \n",
       "...           ...        ...        ...               ...   \n",
       "5210    32.882702  48.581990   2.151754                11   \n",
       "3828     1.844158  77.755383   3.547843                19   \n",
       "2965    -6.544956  13.474710   2.212371                12   \n",
       "3982    19.174126  56.485073  13.930092                 6   \n",
       "3875     4.633405  54.526187  15.758153                11   \n",
       "\n",
       "      CardiovascularCases  HospitalAdmissions  HealthImpactScore  \n",
       "1826                    7                   1          89.130981  \n",
       "4105                    3                   0         100.000000  \n",
       "498                     3                   4         100.000000  \n",
       "874                     7                   3          76.647627  \n",
       "2987                    6                   1         100.000000  \n",
       "...                   ...                 ...                ...  \n",
       "5210                    7                   1         100.000000  \n",
       "3828                    7                   0         100.000000  \n",
       "2965                    6                   5         100.000000  \n",
       "3982                    4                   3          69.959538  \n",
       "3875                    2                   2         100.000000  \n",
       "\n",
       "[4648 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2f92d17-d77b-4bdb-8d59-189f02698142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Health Impact Class: [2.]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the saved model (replace with your actual .pkl file path)\n",
    "model = joblib.load('stacking_model.pkl')  # Make sure to use the correct path to your model\n",
    "\n",
    "# Step 2: Create the input data (must have the same columns as used during training)\n",
    "data = {\n",
    "      # Add the missing column with a placeholder value (0 or None)\n",
    "    'AQI': [120],  # Example input values (replace with your actual input)\n",
    "    'PM10': [40],\n",
    "    'PM2_5': [30],\n",
    "    'NO2': [15],\n",
    "    'SO2': [5],\n",
    "    'O3': [45],\n",
    "    'Temperature': [22],\n",
    "    'Humidity': [55],\n",
    "    'WindSpeed': [5],\n",
    "    'RespiratoryCases': [200],\n",
    "    'CardiovascularCases': [150],\n",
    "    'HospitalAdmissions': [30],\n",
    "    'HealthImpactScore': [80]\n",
    "}\n",
    "\n",
    "# Step 3: Convert input data to DataFrame\n",
    "input_data = pd.DataFrame(data)\n",
    "\n",
    "# Step 4: No scaling applied (since it wasn't during training)\n",
    "input_data_scaled = input_data  # No scaling is done\n",
    "\n",
    "# Step 5: Make predictions\n",
    "prediction = model.predict(input_data_scaled)\n",
    "\n",
    "# Step 6: Output the prediction\n",
    "print(\"Predicted Health Impact Class:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44331b3a-4897-4f9f-8448-360ad533c4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved as 'scaler.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Load the dataset (replace 'path_to_dataset.csv' with your actual dataset file)\n",
    "df = pd.read_csv('D:/Machin Language Projects/air quality/air_quality_health_impact_data.csv')\n",
    "\n",
    "# Define features and target (assuming 'HealthImpactClass' is the target column)\n",
    "X = df.drop(columns=['HealthImpactClass','RecordID'])\n",
    "\n",
    "# Fit the scaler on the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "print(\"Scaler saved as 'scaler.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a506ac3d-d4e4-48b3-a987-11528c3a1615",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c1ac31-205a-4707-9386-e221aeeb34e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5200310,
     "sourceId": 8675842,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 52.058042,
   "end_time": "2024-09-18T12:51:28.121939",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-18T12:50:36.063897",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
